#!/usr/bin/env python3
import argparse
from pathlib import Path
from typing import Optional, List, Dict, Tuple
import pandas as pd
import hashlib

MODEL_ORDER = ["baseline", "nacl_ft_small", "mix154_ft_small"]

def _find_first_col(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:
    cols = {c.lower(): c for c in df.columns}
    for cand in candidates:
        if cand.lower() in cols:
            return cols[cand.lower()]
    return None

def _safe_bool_series(df: pd.DataFrame, col: str) -> pd.Series:
    s = df[col]
    if pd.api.types.is_bool_dtype(s):
        return s.fillna(False)
    if pd.api.types.is_numeric_dtype(s):
        return s.fillna(0).astype(int) != 0
    return s.astype(str).str.lower().isin(["true","1","yes","y","t"])

def _hash_series_str(s: pd.Series) -> pd.Series:
    def h(x: str) -> str:
        return hashlib.md5(x.encode("utf-8", errors="ignore")).hexdigest()
    return s.fillna("").astype(str).map(h)

def parse_prompt_model(eval_csv: Path) -> Tuple[str, str]:
    # expected: <root>/processed/<prompt>/<model>/eval.csv
    model = eval_csv.parent.name
    prompt = eval_csv.parent.parent.name
    return prompt, model

def compute_metrics(df: pd.DataFrame, topk: int = 8) -> Dict:
    valid_col = _find_first_col(df, ["parse_ok","valid","is_valid","is_valid_cif","cif_valid","parsed","parse_success","success","ok"])
    formula_col = _find_first_col(df, ["reduced_formula","formula","cell_formula","pretty_formula"])
    sgnum_col = _find_first_col(df, ["spacegroup_number", "space_group_number", "sg_number", "spacegroup_num"])
    sgsym_col = _find_first_col(df, ["spacegroup_symbol", "space_group_symbol", "sg_symbol", "spacegroup"])
    hash_col = _find_first_col(df, ["cif_hash", "hash"])
    cif_text_col = _find_first_col(df, ["generated_cif", "cif_text", "cif"])

    if valid_col is None:
        valid = pd.Series([False] * len(df))
    else:
        valid = _safe_bool_series(df, valid_col)

    dfv = df[valid].copy()
    n = len(df)
    nv = len(dfv)
    validity = (nv / n) if n else 0.0

    # uniqueness among valid
    if nv == 0:
        uniq_valid = 0
    else:
        if hash_col:
            uniq_valid = dfv[hash_col].nunique(dropna=True)
        elif cif_text_col:
            uniq_valid = _hash_series_str(dfv[cif_text_col]).nunique()
        else:
            if formula_col and sgnum_col:
                uniq_valid = (dfv[formula_col].astype(str) + "|" + dfv[sgnum_col].astype(str)).nunique()
            elif formula_col:
                uniq_valid = dfv[formula_col].astype(str).nunique()
            else:
                uniq_valid = nv
    uniqueness_valid = (uniq_valid / nv) if nv else 0.0

    # formula summary
    if nv and formula_col:
        unique_formulas = dfv[formula_col].astype(str).nunique()
        vc = dfv[formula_col].astype(str).value_counts()
        top_items = vc.head(topk)
        others = int(vc.iloc[topk:].sum()) if len(vc) > topk else 0
        top_formula = ", ".join([f"{k}({v})" for k, v in top_items.items()])
        if others > 0:
            top_formula += f", others({others})"
    else:
        unique_formulas = 0
        top_formula = ""

    # sg summary
    if nv and sgnum_col:
        unique_sg = dfv[sgnum_col].nunique()
        vc2 = dfv[sgnum_col].value_counts()
        top_items2 = vc2.head(topk)
        others2 = int(vc2.iloc[topk:].sum()) if len(vc2) > topk else 0
        if sgsym_col:
            sym_map = (dfv.groupby(sgnum_col)[sgsym_col]
                       .agg(lambda x: x.astype(str).value_counts().index[0] if len(x) else "")
                       .to_dict())
            parts = []
            for num, cnt in top_items2.items():
                parts.append(f"{num}:{sym_map.get(num,'') }({cnt})".replace(" ", ""))
            top_sg = ", ".join(parts)
        else:
            top_sg = ", ".join([f"{k}({v})" for k, v in top_items2.items()])
        if others2 > 0:
            top_sg += f", others({others2})"
    else:
        unique_sg = 0
        top_sg = ""

    return dict(
        num_samples=n,
        num_valid=nv,
        validity=round(validity, 4),
        uniq_valid=uniq_valid,
        uniqueness_valid=round(uniqueness_valid, 4),
        unique_formulas=unique_formulas,
        unique_spacegroups=unique_sg,
        top_formula=top_formula,
        top_spacegroup=top_sg,
    )

def to_markdown(df_all: pd.DataFrame) -> str:
    md = []
    md.append("# Demo6 — Prompt Sweep Summary (from eval.csv)\n")
    md.append("Auto-generated by `scripts/demo6_summarize_from_eval.py`.\n")

    md.append("## All runs (prompt × model)\n")
    md.append(df_all.to_markdown(index=False))
    md.append("")

    md.append("## Macro-average over prompts (per model)\n")
    agg = (df_all.groupby("model_id")
           .agg(validity_mean=("validity", "mean"),
                uniqueness_mean=("uniqueness_valid", "mean"),
                formula_unique_mean=("unique_formulas", "mean"),
                sg_unique_mean=("unique_spacegroups", "mean"))
           .reset_index())
    md.append(agg.to_markdown(index=False))
    md.append("")
    return "\n".join(md)

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--root", required=True, help="reports/demo6_prompt_sweep_n100")
    ap.add_argument("--out_csv", required=True)
    ap.add_argument("--out_md", required=True)
    ap.add_argument("--topk", type=int, default=8)
    args = ap.parse_args()

    root = Path(args.root)
    eval_paths = sorted(root.glob("processed/*/*/eval.csv"))
    if not eval_paths:
        raise SystemExit(f"[ERROR] No eval.csv found under {root}/processed/*/*/eval.csv")

    rows = []
    for ep in eval_paths:
        prompt, model = parse_prompt_model(ep)
        df = pd.read_csv(ep)
        m = compute_metrics(df, topk=args.topk)
        rows.append({
            "prompt_id": prompt,
            "model_id": model,
            **m,
            "eval_csv": str(ep),
        })

    out_df = pd.DataFrame(rows)
    out_df["model_id"] = pd.Categorical(out_df["model_id"], categories=MODEL_ORDER, ordered=True)
    out_df = out_df.sort_values(["prompt_id", "model_id"])

    Path(args.out_csv).parent.mkdir(parents=True, exist_ok=True)
    out_df.to_csv(args.out_csv, index=False)

    Path(args.out_md).parent.mkdir(parents=True, exist_ok=True)
    Path(args.out_md).write_text(to_markdown(out_df[[
        "prompt_id","model_id",
        "num_samples","num_valid","validity",
        "uniq_valid","uniqueness_valid",
        "unique_formulas","unique_spacegroups",
        "top_formula","top_spacegroup"
    ]]), encoding="utf-8")

if __name__ == "__main__":
    main()
